{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataiku/code-envs/python/TONE_py3_env/lib/python3.6/site-packages/packaging/version.py:114: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release\n",
      "  DeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import dataiku\n",
    "import dataikuapi\n",
    "from dataiku import pandasutils as pdu\n",
    "from dataiku import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import RobertaTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import RobertaForMaskedLM, RobertaModel\n",
    "from transformers import TFRobertaForSequenceClassification, TFRobertaModel\n",
    "from transformers import pipeline\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_input(sentences,tokenizer):\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "  \n",
    "    for x in sentences:\n",
    "        inputs = tokenizer.encode_plus(x, \n",
    "                                          add_special_tokens=True, \n",
    "                                          return_token_type_ids=True,\n",
    "                                          truncation=True, \n",
    "                                          max_length=max_length)\n",
    "        i, t = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
    "        m = [1] * len(i)\n",
    "\n",
    "        padding_length = max_length - len(i)\n",
    "\n",
    "        i = i + ([pad_token] * padding_length)\n",
    "        m = m + ([0] * padding_length)\n",
    "        t = t + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "        input_ids.append(i)\n",
    "        attention_masks.append(m)\n",
    "        token_type_ids.append(t)\n",
    "  \n",
    "    return [np.asarray(input_ids), \n",
    "            np.asarray(attention_masks), \n",
    "            np.asarray(token_type_ids)]\n",
    "\n",
    "def example_to_features(input_ids, attention_masks, token_type_ids, y):\n",
    "    return {\"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_masks,\n",
    "            \"token_type_ids\": token_type_ids},y\n",
    "\n",
    "def predict(tokenizer, model, sentences):\n",
    "    tf_batch = tokenizer(sentences, max_length=512, padding=True, truncation=True, return_tensors='tf')\n",
    "    tf_outputs = model(tf_batch)\n",
    "    tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "    label = tf.argmax(tf_predictions, axis=1)\n",
    "    label = label.numpy()\n",
    "    return label\n",
    "\n",
    "def predict_alt(tokenizer, model, sentences):\n",
    "    tf_batch = tokenizer(sentences, max_length=512, padding=True, truncation=True, return_tensors='tf')\n",
    "    tf_outputs = model(tf_batch)\n",
    "    tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "    label = tf.argmax(tf_predictions, axis=1)\n",
    "    label = label.numpy()\n",
    "    return label, tf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NL = '/data/library/python/robbert-v2-dutch-base'\n",
    "MODEL_EN = '/data/library/python/roberta-base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train sentence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at /data/library/python/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_nl = TFRobertaForSequenceClassification.from_pretrained(MODEL_NL,num_labels=2)\n",
    "tokenizer_nl = RobertaTokenizer.from_pretrained(MODEL_NL)\n",
    "\n",
    "# model_en = TFRobertaForSequenceClassification.from_pretrained(MODEL_EN,num_labels=4)\n",
    "# tokenizer_en = RobertaTokenizer.from_pretrained(MODEL_EN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Dataset('df_results_mvb_big_para_labelled').get_dataframe().set_index('col_0')\n",
    "#adjustment for alternative training (only 2 labels)\n",
    "df['label2']=df['label'].copy()\n",
    "df.loc[df['label']==1,'label2'] = 0\n",
    "df.loc[df['label']==2,'label2'] = 1\n",
    "df_nl = df[df['dc:language']=='nl'].reset_index()\n",
    "df_en = df[df['dc:language']=='en'].reset_index()\n",
    "dft = df_nl[df_nl.label.isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataiku/code-envs/python/TONE_py3_env/lib64/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# necessary step because otherwise the tokenizer produces incorrect token during training\n",
    "for row in dft.index:\n",
    "    dft.loc[row, 'dnb_nlp:sentence'] = dft.loc[row, 'dnb_nlp:sentence'].replace(\"\\n\", \" \")\n",
    "# for row in df_en.index:\n",
    "#     df_en.loc[row, 'dnb_nlp:sentence'] = df_en.loc[row, 'dnb_nlp:sentence'].replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dutch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (900,), \n",
      "Test dataset shape: (101,)\n"
     ]
    }
   ],
   "source": [
    "X = (np.array(dft['dnb_nlp:sentence']))\n",
    "y = (np.array(dft['label2']))\n",
    "X = np.array([test.encode(\"ascii\", \"ignore\").decode() for test in list(X)])\n",
    "X = np.array([test.replace('\\n',' ') for test in list(X)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=13) \n",
    "\n",
    "print(\"Train dataset shape: {0}, \\nTest dataset shape: {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "pad_token = 0\n",
    "pad_token_segment_id = 0\n",
    "max_length = 512\n",
    "\n",
    "X_test_input = convert_to_input(X_test,tokenizer_nl)\n",
    "X_train_input = convert_to_input(X_train,tokenizer_nl)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train_input[0],X_train_input[1],X_train_input[2],y_train)).map(example_to_features).shuffle(100).batch(32).repeat(5)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test_input[0],X_test_input[1],X_test_input[2],y_test)).map(example_to_features).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/logging/__init__.py:8: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  # not be used in advertising or publicity pertaining to distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2b1cc3c5f8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f2b1aabb778> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2b1cc3c5f8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f2b1aabb778> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2b1cc3c5f8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f2b1aabb778> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f2b181198c8> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f2b181198c8> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING: AutoGraph could not transform <function wrap at 0x7f2b181198c8> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.7390 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 2828s 19s/step - loss: 0.5548 - accuracy: 0.7392 - val_loss: 0.3263 - val_accuracy: 0.8812\n",
      "Epoch 2/5\n",
      "145/145 [==============================] - 2703s 19s/step - loss: 0.2153 - accuracy: 0.9088 - val_loss: 0.3713 - val_accuracy: 0.8812\n",
      "Epoch 3/5\n",
      "145/145 [==============================] - 2603s 18s/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.5443 - val_accuracy: 0.9010\n",
      "Epoch 4/5\n",
      "145/145 [==============================] - 2563s 18s/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 0.6866 - val_accuracy: 0.8614\n",
      "Epoch 5/5\n",
      "145/145 [==============================] - 2586s 18s/step - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.7577 - val_accuracy: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f29b8205908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, \n",
    "                                     epsilon=1e-08, \n",
    "                                     clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) #can be used when there are two or more label classes\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model_nl.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "model_nl.fit(train_ds, epochs=5, validation_data=test_ds) #train model for finxed number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lc1UMaK3 is code of model_nl_methods\n",
    "model_dir = '/data/dataiku/managed_folders/solvency2/TV_TEXTMINING/Lc1UMaK3'\n",
    "model_nl.save_pretrained(save_directory=model_dir)\n",
    "\n",
    "# folder = dataiku.Folder('c9VWnxpk')  \n",
    "# model_nl.save_pretrained(save_directory=folder.get_path())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance Dutch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at /data/dataiku/managed_folders/solvency2/TV_TEXTMINING/Lc1UMaK3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = dict()\n",
    "tokenizer = dict()\n",
    "\n",
    "model_dir = '/data/dataiku/managed_folders/solvency2/TV_TEXTMINING/Lc1UMaK3'\n",
    "model['nl'] = TFRobertaForSequenceClassification.from_pretrained(model_dir,num_labels=2)\n",
    "tokenizer['nl'] = RobertaTokenizer.from_pretrained(MODEL_NL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dataiku/code-envs/python/TONE_py3_env/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-+------------+---+++--+-+-+-----------+++--------------+--+-++-+-+-+-+-+--+-+-+---+---+-+------+---+-----+++--+---+-+++---+-----++-+---++-+-+-+---+++----+---+-+++-+-++-+-+-++---+----------+-----------+---++---+--+-------+---+--+------++-----+--+-+--+++------++-+-----------++++-----++------+--+--+-+-++--+------+-+-++++--++--++++++-----+-+------+-+---+++----+---+------+-+++---+------+-------------+++----------+----+--++------+++++---+--+----+---------+-----+++--+-----++--------+--+----------------+-+-+---+------------++------+--++---------++------++---------+-+----+---------++--+-+--++----+------++-+----------+-----+--+-------+-----------++-+++--+--------+-+-+-++-----+----+-+----------+-+----+++++++-----+------+-----------------------------+------+-+------------+------------------+--+-----+-----------------+---+-+----+--+-+--+-+-+-------------+-++-++-++-++-+--+++---------++--------+----------------+--+-++--++-----+--+--+---+----------+------+---++----------------+--------+------++--+-+++[[739  12]\n",
      " [  6 244]]\n",
      "0.9820179820179821\n",
      "0.9822506771751738\n",
      "0.9820179820179821\n",
      "0.9820885345763282\n"
     ]
    }
   ],
   "source": [
    "# #Whole labelled set\n",
    "# dft['prediction'] = -1  # sentence is not processed\n",
    "\n",
    "# for row in dft.index:\n",
    "#     p = predict(tokenizer['nl'],model['nl'], [dft.loc[row, 'dnb_nlp:sentence']])\n",
    "#     print(\"+\" if p==1 else \"-\", end='')\n",
    "#     dft.loc[row, 'prediction'] = p\n",
    "\n",
    "# #Sentences wrong prediction\n",
    "# #print(dft[(dft['label']!=dft['prediction'])]['dnb_nlp:sentence'].values)\n",
    "\n",
    "# print(confusion_matrix(dft['label2'], dft['prediction']))\n",
    "# print(accuracy_score(dft['label2'], dft['prediction']))\n",
    "# print(precision_score(dft['label2'], dft['prediction'],average='weighted'))\n",
    "# print(recall_score(dft['label2'], dft['prediction'],average='weighted'))\n",
    "# print(f1_score(dft['label2'], dft['prediction'],average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[677   0]\n",
      " [  0 223]]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Training set\n",
    "X = (np.array(dft['dnb_nlp:sentence']))\n",
    "y = (np.array(dft['label2']))\n",
    "X = np.array([test.encode(\"ascii\", \"ignore\").decode() for test in list(X)])\n",
    "X = np.array([test.replace('\\n',' ') for test in list(X)])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=13)\n",
    "\n",
    "y_predict = []\n",
    "for i in range(0,len(X_train)):\n",
    "    p,prob = predict_alt(tokenizer['nl'],model['nl'], [X_train[i]])\n",
    "    #print(\"+\" if p==1 else \"-\", end='')\n",
    "    if p != y_train[i]:\n",
    "        print(p)\n",
    "        print(y_train[i])\n",
    "        print(prob)\n",
    "        print(X_train[i])\n",
    "    y_predict = y_predict + list(p)\n",
    "\n",
    "print(confusion_matrix(y_train,y_predict))\n",
    "print(accuracy_score(y_train, y_predict))\n",
    "print(precision_score(y_train, y_predict,average='weighted'))\n",
    "print(recall_score(y_train, y_predict,average='weighted'))\n",
    "print(f1_score(y_train, y_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "1.0\n",
      "tf.Tensor([[9.9931908e-01 6.8094913e-04]], shape=(1, 2), dtype=float32)\n",
      "goed Binnen het onroerend goed is de ambitie van het fonds om panden energiezuinig te krijgen . Dit kan worden bereikt door het bouwen met milieubesparende maatregelen zoals zonne-energie , isolatie , zonnepanelen ( voor warm water ) en warm-koud opslag in de grond . Een\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[6.8737013e-04 9.9931264e-01]], shape=(1, 2), dtype=float32)\n",
      "Hypotheken Er is in deze tijd van lage ( risicovrije)rente op obligaties een zoektocht naar alternatieve ' veilige havens ' . Het beleggen in Nederlandse hypotheken is hierop een antwoord . Dit wordt onderbouwd door het gunstige macro-economische klimaat , de dalende werkloosheid , de geprognosticeerde stijging van woningprijzen , alsmede de lage defaults op woninghypotheken en de aantrekkelijke marge en de relatief lage kapitaaleis voor pensioenfondsen . Net als in 2017 was in 2018 de hypotheekomzet hoog . Dit is vooral te verklaren door de hoogte van de gemiddelde hypotheeksom . In 2018 steeg bij woningverkopen de vierkante meterprijs gemiddeld met 8,6 % . Het aantal transacties daalde in 2018 doordat er minder woningen te koop werden aangeboden . Ook stonden in het vierde kwartaal van 2018 huizen langer te koop dan de afgelopen jaren . Dit lijkt een signaal te zijn dat de huizenmarkt aan het afkoelen is . De risico-opslagen zijn over heel 2018 gemiddeld met 6 basispunten toegenomen . Dit komt doordat de risico-opslagen voor de kortere looptijden zijn toegenomen . Voor de langere looptijden zijn de opslagen iets afgenomen . Hypotheekrentes waren gemiddeld aan het begin en het eind van 2018 vrijwel gelijk .\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[0.1067798  0.89322025]], shape=(1, 2), dtype=float32)\n",
      "Aansluiting bij overall prioriteiten duurzaam beleggen SPIN richt zich in haar MVB beleid nadrukkelijk op de themas ( Corporate ) Governance en Klimaatverandering . SPIN verlangt van haar dienstverleners dat een materieel deel van de stewardship activiteiten van deze dienstverleners op deze twee themas is gericht . Op deze twee themas voert SPIN op een proactieve manier haar stewardship activiteiten uit , d.w.z.\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[0.00662621 0.9933739 ]], shape=(1, 2), dtype=float32)\n",
      "Deelnemersonderzoek Het pensioenfonds heeft medio 2021 een uitgebreid deelnemersonderzoek gehouden om de risicohouding en de beelden die deelnemers hebben bij verantwoord beleggen , te onderzoeken . Het bestuur was tevreden over de respons . Van de aangeschreven deelnemers reageerde 27% van de actieve deelnemers , 16% van de gewezen deelnemers en 45% van de gepensioneerden .\n",
      "[0]\n",
      "1.0\n",
      "tf.Tensor([[9.9918896e-01 8.1103551e-04]], shape=(1, 2), dtype=float32)\n",
      "SBZ Pensioen 51 8 Governance 8.1 Maatschappelijk verantwoord ondernemen Verantwoord ondernemen is steeds meer onderwerp van maatschappelijke discussie . Overheden , burgers en bedrijven hebben met zijn allen de plicht te komen tot een reductie van CO2-uitstoot . Op 12 december 2015 sloten de bijna 200 deelnemende landen in Parijs een klimaatakkoord ( als opvolger van het protocol van Kyoto uit 1997 ) . Het doel is de opwarming van de atmosfeer te beperken tot 2C met als streefwaarde 1,5C ( in de jaren 2050-2100 ; dit betekent een halvering van de uitstoot ten opzichte van 1990 ) . In 2017 bracht de High Level Expert Group ( HLEG ) van de EU een voorlopig rapport uit met aanbevelingen tot wijzigingen in EU-regels en financieel beleid om duurzame investeringen te faciliteren . Ook besloot het UN Global Compact Forum dat de tabaksindustrie niet langer meer welkom is bij het initiatief . Naast milieu staan ook eerlijk bestuur en oog voor alle belanghebbenden steeds hoger op de agenda . Ook SBZ Pensioen wil op een eerlijke en verantwoorde manier werken . Dit verwachten we ook van onze uitbestedingspartijen en de ondernemingen waarin we beleggen .\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[0.18081975 0.81918025]], shape=(1, 2), dtype=float32)\n",
      "Het toepassen van positieve selectie wordt momenteel nog niet toegepast in de portefeuille . Deze vorm van maatschappelijk verantwoord beleggen vereist namelijk dat Bpf Foodservice specifieke bedrijven en sectoren definieert waarvan het pensioenfonds overtuigd is dat deze beter zullen presteren dan de benchmark , omdat deze bedrijven en sectoren bijvoorbeeld een hogere ESG-score Deze vorm van maatschappelijk verantwoord beleggen wordt wel tot op zekere hoogte toegepast bij de actieve credit fondsen , aangezien de ESG-score meeweegt in de selectie van specifieke obligaties .\n",
      "[0]\n",
      "1.0\n",
      "tf.Tensor([[0.99879044 0.00120956]], shape=(1, 2), dtype=float32)\n",
      "stabiele , veelal met inflatie oplopende , rendementen en een relatief lage correlatie met andere SPF onderschrijft de ESG due diligence stappen in overeenstemming met het OESO-richtsnoer . SPF verwacht ook beleggingscategorien .\n",
      "[0]\n",
      "1.0\n",
      "tf.Tensor([[0.99295723 0.00704282]], shape=(1, 2), dtype=float32)\n",
      "Engagement betreft het voeren van een dialoog met een onderneming om zo invloed uit te oefenen en een visie of standpunt over te brengen . Vanuit de gedachte dat het meer impact heeft dan stemmen met de voeten  , wordt beoogd de onderneming te overtuigen van de relevantie van dat standpunt . Indien een onderneming ondanks onze engagement inspanning binnen een redelijke termijn niet te overtuigen is van de relevantie van het volgen van ons standpunt leidt dit tot desinvestering . SPIN verlangt van haar dienstverleners dat zij engagement toepassen in gevallen waar een materieel issue speelt vanuit het perspectief van lange termijn rendement en omgang met ESG-factoren . SPIN verwacht daarbij dat de dienstverlener voor zijn engagement inspanning duidelijke doelen formuleert en de voortgang daarvan inzichtelijk maakt . SPIN voert daarover met een vaste frequentie gesprekken met de betrokken managers om het stewardship gedrag van deze partijen te kunnen beoordelen en benvloeden .\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[0.00132077 0.9986792 ]], shape=(1, 2), dtype=float32)\n",
      "deze risicos overwogen en verwerkt rente , beleggingsrendementen , in de buffer voor het in de 87 Stichting Pensioenfonds Coram Grote posten zijn aan te duiden als een vorm van concentratierisico . Om te bepalen welke posten hieronder vallen moeten per beleggingscategorie alle instrumenten met dezelfde debiteur worden gesommeerd . Als grote post wordt aangemerkt elke post die meer dan 2% van het balanstotaal uitmaakt . Dit betreft per 31 december 2018 de volgende posten : ( *  1.000 ) BNPP E FTSE EPRA NDE UCITS ETF QD H EURD NT WRD CUS ESG EUR HG EQ I C MSCI EMERGING MKT EX CONTROVERSI WEAPONS SUSTAINABLE BOND WORLD CORPORA I H EUR C BNP PARIBAS LDI SOLUT 5 10Y EUR PC BNP PARIBAS LDI SOLUT 15 20Y EUR BNP PARIBAS LDI SOLUT 20 25Y EUR BNP PARIBAS LDI SOLUT 25 35Y EUR SPDR EMERGING MKTS LOCAL BD 2018 2.997 17.540 2.920 15.581 2.858 5.577 4.504 3.649 3.051 3.094 PARVEST BOND WORLD HIGH YIELD I C In het algemeen geldt dat concentratierisico kan optreden als een adequate spreiding van activa en passiva ontbreekt . Concentratierisicos kunnen optreden bij een concentratie van de portefeuille in regios , economische sectoren of tegenpartijen . Een portefeuille\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[6.0130906e-04 9.9939871e-01]], shape=(1, 2), dtype=float32)\n",
      "Op basis van een evaluatie is besloten om het securities lending-beleid uit te breiden met obligaties . Vanaf 2022 Het bestuur volgt de voorkeur van de deelnemers en heeft oog voor maatschappelijke trends en wil vanuit haar worden er weer aandelen en obligaties uitgeleend . Eerder is in 2015 besloten om het uitlenen van obligaties te maatschappelijke rol bijdragen aan een duurzaam klimaat . Het bestuur onderkent dat de ontwikkelingen op dit beindigen vanwege de gedaalde uitleenvergoeding op obligaties . Het bestuur heeft het uitleenbeleid gevalueerd gebied snel gaan en kan hierbij periodiek toetsen , bij de deelnemers of andere belanghebbenden , of het beleid en verwacht op basis van de actuele marktomstandigheden weer hogere uitleenvergoedingen en heeft aangescherpt moet worden .\n",
      "[0]\n",
      "1.0\n",
      "tf.Tensor([[0.99421036 0.00578969]], shape=(1, 2), dtype=float32)\n",
      "Onze ambitie is om met onze beleggingskeuzes bij te dragen aan zowel welvaart als welzijn . Wij kiezen hiermee voor een verantwoord rendement omdat we ons bewust zijn van onze maatschappelijke positie als pensioenfonds en institutionele belegger . Wij nemen , samen met onze inzet voor een financieel goed pensioen , verantwoordelijkheid te voor de effecten van onze beleggingen op de wereld waarin onze deelnemers met pensioen gaan . We willen negatieve effecten voor de samenleving voorkomen en waar mogelijk via engagement en/of stembeleid een positieve bijdrage leveren . Wij hebben PRI ondertekend in 2020 . Hiermee willen we voldoen aan marktnormen en op basis van periodieke assessments eventuele acties benoemen en implementeren om ons MVB beleid verder vorm te geven .\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[0.28182116 0.71817887]], shape=(1, 2), dtype=float32)\n",
      "2021 Stichting Pensioenfonds TNT Express in liquidatie Biodiversiteit 75 % of lager .  Bedrijven\n",
      "[0]\n",
      "1.0\n",
      "tf.Tensor([[0.6514786 0.3485214]], shape=(1, 2), dtype=float32)\n",
      ": aantal keren dat gestemd is Aandeelhoudersvergaderingen 3178 5146 5118 28 Aantal Stembiljetten Gestemd Niet gestemd Stemgedrag : wijze van stemmen Voorstellen management Voorstellen aandeelhouders Totaal Aantal 61672 1759 63431 Voor 54482 797 55279 Tegen Onthouden Niet gestemd 6590 950 7540 303 12 315 297 0 297 Pagina 40 Jaarverslag 2016 Stichting Bedrijfstakpensioenfonds voor het Beroepsvervoer over de Weg Doelinvesteringen Doelinvesteringen zijn investeringen die aannemelijk positief kunnen bijdragen aan het verwezenlijken van de Sustainable Development Goals ( SDG ) van de VN . De SDG zijn de opvolgers van de UN Millennium Goals . De termijn\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[3.4364645e-04 9.9965632e-01]], shape=(1, 2), dtype=float32)\n",
      "monetaire autoriteiten bleven in 2021 een accomoderend beleid voeren , wat een gunstig klimaat voor aandelen opleverde . Ondanks zorgen tegen het einde van het jaar over de omikron variant , bleef het sentiment op aandelenmarkten relatief gunstig . Aandelen in de energiesector deden het erg goed en stegen gemiddeld met ruim 45 % door de fors opgelopen olieprijs . Daarnaast bleven aandelen uit de IT-sector wederom in trek . Door de wereldwijde pandemie en het op grote schaal thuiswerken werd het gebruik van nieuwe applicaties gestimuleerd . Het rendement\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[0.4781828 0.5218172]], shape=(1, 2), dtype=float32)\n",
      "Gedurende 2019 werkt het Fonds met de vermogensbeheerder aan een verdere screening van onze portefeuille uit om kwantitatief weer te geven welk deel van de portefeuille voldoet aan de in onze \" investment beliefs \" geformuleerde doelstelling t.a.v. maatschappelijk verantwoord beleggen en hoe wij kunnen toegroeien naar dit \" gentegreerd \" beleid .\n",
      "[1]\n",
      "0.0\n",
      "tf.Tensor([[0.04790188 0.95209813]], shape=(1, 2), dtype=float32)\n",
      "Actief aandeelhouderschap Als aandeelhouder is het Spoorwegpensioenfonds mede-eigenaar van een onderneming . Dit stelt het fonds in staat om invloed uit te oefenen op het beleid van ondernemingen . Deze invloed wordt gebruikt om ondernemingen aan te zetten hun prestaties op het gebied van MVB te verbeteren . Het pensioenfonds doet dit door het uitvoeren van engagement en het stemmen op aandeelhoudersvergaderingen .\n",
      "[[64 10]\n",
      " [ 6 21]]\n",
      "0.8415841584158416\n",
      "0.8509650043345349\n",
      "0.8415841584158416\n",
      "0.8448465536208793\n"
     ]
    }
   ],
   "source": [
    "#Test set\n",
    "X = (np.array(dft['dnb_nlp:sentence']))\n",
    "y = (np.array(dft['label2']))\n",
    "X = np.array([test.encode(\"ascii\", \"ignore\").decode() for test in list(X)])\n",
    "X = np.array([test.replace('\\n',' ') for test in list(X)])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=13)\n",
    "\n",
    "y_predict = []\n",
    "for i in range(0,len(X_test)):\n",
    "    p,prob = predict_alt(tokenizer['nl'],model['nl'], [X_test[i]])\n",
    "    #print(\"+\" if p==1 else \"-\", end='')\n",
    "    if p != y_test[i]:\n",
    "        print(p)\n",
    "        print(y_test[i])\n",
    "        print(prob)\n",
    "        print(X_test[i])\n",
    "    y_predict = y_predict + list(p)\n",
    "\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(precision_score(y_test, y_predict,average='weighted'))\n",
    "print(recall_score(y_test, y_predict,average='weighted'))\n",
    "print(f1_score(y_test, y_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Whole labelled set\n",
    "# df_nl['prediction'] = -1  # sentence is not processed\n",
    "\n",
    "# for row in df_nl.index:\n",
    "#     p = predict(tokenizer['nl'],model['nl'], [df_nl.loc[row, 'dnb_nlp:sentence']])\n",
    "#     print(\"+\" if p==1 else \"-\", end='')\n",
    "#     df_nl.loc[row, 'prediction'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = dataiku.api_client()\n",
    "# project = client.get_project(\"CLIMATEANALYSIS\")\n",
    "# name = 'results_labelled_specificity_incl_prediction_alt'\n",
    "# d = dataikuapi.dss.dataset.DSSManagedDatasetCreationHelper(project,name)\n",
    "# d = d.with_store_into('filesystem_managed_solvency2')\n",
    "# d.create(name)\n",
    "# output = Dataset(name)\n",
    "# output.write_with_schema(df_nl, dropAndCreate=True)"
   ]
  }
 ],
 "metadata": {
  "createdOn": 1661501507121,
  "creator": "A.W.M.van.Ool",
  "customFields": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (env TONE_py3_env)",
   "language": "python",
   "name": "py-dku-venv-tone_py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "modifiedBy": "A.W.M.van.Ool",
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
